{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# plot formatting\n",
    "plt.rcParams[\"figure.figsize\"] = (16,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains 5000 customer queries at an online retailer, which are classified into seven topics such as \"Shipping\", \"Product Availability\", \"Returns & Refunds\", etc. Your job is to build a multi-class classifier that can automatically classify new incoming queries into these topics, so that they can be handled by the appropriate department.\n",
    "\n",
    "For this assignment, select:\n",
    "\n",
    "1. one multi-class classifier (Naive Bayes, Logistic, Decision Tree, or SVM) whose code is provided in class handouts, \n",
    "\n",
    "2. one ensemble classifier whose code is also provided (Random Forest or XGBoost), and \n",
    "\n",
    "3. one other model of your choice whose code is NOT provided in class handouts (this will require some independent research on the Internet). \n",
    "\n",
    "For each classifier, use three kinds of input feature vectors: \n",
    "\n",
    "1. TF-IDF vector, \n",
    "\n",
    "2. word vectors (Stanford's Glove, Google's Word2Vec, or Facebook's FastText), and \n",
    "\n",
    "3. document vectors (Doc2Vec). \n",
    "\n",
    "Train the three models using training data, report classification metrics using validation data, comment on which model will be your preferred choice for text classification for this data and why. \n",
    "\n",
    "Also, test your model with some (at least 5) self-created queries not in the dataset to check if your three models can classify them accurately. Submit your code and output as a Jupyter file. \n",
    "\n",
    "The assignment will be graded based on your ability to teach yourself a new classifier, your ability to make intelligent choices (e.g., hyper-parameters), and your ability to \"communicate\" your analysis in a comprehensive, understandable manner with proper documentation. Use appropriate graphics if appropriate. The professor or TA will not answer questions such as \"what classification metrics should I report\" or \"should I do dimension reduction before using a classifier\" or \"what type of documentation should I include\". These are choices for YOU to make (you cannot \"outsource\" that thinking to the professor), but your documentation must clearly describe AND EXPLAIN any choices that you make. There will be no credit for copying and pasting code from class handouts. You will be penalized for inadequate documentation; think for yourself what documentation is needed to convey what you did and why you did it to an outsider who does not know anything about this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   question  5000 non-null   object\n",
      " 1   topic     5000 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 78.2+ KB\n",
      "None \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi! If I sign up for your email list, can I se...</td>\n",
       "      <td>Sales/Promotions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm going to be out of the country for about a...</td>\n",
       "      <td>Shipping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I was wondering if you'd be able to overnight ...</td>\n",
       "      <td>Shipping</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question             topic\n",
       "0  Hi! If I sign up for your email list, can I se...  Sales/Promotions\n",
       "1  I'm going to be out of the country for about a...          Shipping\n",
       "2  I was wondering if you'd be able to overnight ...          Shipping"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Customer_Service_Questions_Multiclass.csv')\n",
    "print(data.info(), '\\n')\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of Labels\n",
    "\n",
    "Looking at the distribution of each of the 7 query classese. The two smallest classes appear to be `Sales/Promotions` and  `OmniChannel`. We expect that our models may have a harder time trying to classify these. Also the small sample size of 5,000 may better suit ML models over other Deep-Learning models that may require larger datasets for training\n",
    "\n",
    "Taking a closer look at the data it also appears as if some data augmentation has been used. This means more repeated words with certain variations may appear. Not a very diverse set for training could influence impact of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Frequency of Query Categories'}, ylabel='Category'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# See classification categfgories\n",
    "data.topic.value_counts().sort_values().plot(kind='barh', title='Frequency of Query Categories', \n",
    "                                             xlabel='Category', ylabel='Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Cloud per Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abf06e498f99430386b745f2aa622af8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='topic', index=1, options=('Sales/Promotions', 'Shipping', 'Product…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_word_cloud(topic: str = 'Shipping')>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from wordcloud import WordCloud\n",
    "from nltk.corpus import stopwords\n",
    "import ipywidgets as widgets\n",
    "\n",
    "\n",
    "def plot_word_cloud(topic:str='Shipping'):\n",
    "    # stop words for removal\n",
    "    STOPWORDS = stopwords.words('english')\n",
    "    # getting text for plotting filtering by topic\n",
    "    text = \" \".join(words for words in data[data['topic'].eq(topic)].question.tolist())\n",
    "    # plotting configuration\n",
    "    plt.figure(figsize=(16,8))\n",
    "    wordcloud = WordCloud(background_color='white', max_words=100, stopwords=STOPWORDS).generate(text)\n",
    "    plt.style.use(\"dark_background\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "\n",
    "widgets.interact(plot_word_cloud, topic=data.topic.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that there are some key words that seem to be more prevelent depending on the question topic. For example\n",
    "\n",
    "| Topic | Common Word |\n",
    "|---|---|\n",
    "| Availability | Looking|\n",
    "| Sale/Promo | Sale |\n",
    "| Shipping | Receive |\n",
    "| Specifications | Know |\n",
    "| Ominchannel | Store |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting raw data to Textacy (Spacy) docs in batches. Loading in batches helps speed-up processing. Spacy also provides improved lemmatization, POS and dependency parsers that can be used for improved cleaning this helps expedite cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textacy\n",
    "\n",
    "\"\"\"Create Textacy Corpus for fast loading\"\"\"\n",
    "# spacy library\n",
    "library = 'en_core_web_sm'\n",
    "# questions\n",
    "questions = data.question.tolist()\n",
    "# meta in dict format\n",
    "topics = [{'topic':topic} for topic in data.topic.tolist()]\n",
    "# create records\n",
    "records = zip(questions, topics)\n",
    "# create corpus\n",
    "corpus = textacy.Corpus(lang=library)\n",
    "# add to corpus\n",
    "corpus.add_records(records=records, batch_size=50, n_process=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning\n",
    "- using spacy to: remove 1) punctuations, 2) spaces, 3) spaces 4) Numeric POS 5) product codes 6) one letter from contractions (except e for email) 6) any special cases\n",
    "    - removing product item codes using regex pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>topic</th>\n",
       "      <th>clean_question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi! If I sign up for your email list, can I se...</td>\n",
       "      <td>Sales/Promotions</td>\n",
       "      <td>hi sign email list select email exclusively sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm going to be out of the country for about a...</td>\n",
       "      <td>Shipping</td>\n",
       "      <td>go country week travel go get animal print jum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I was wondering if you'd be able to overnight ...</td>\n",
       "      <td>Shipping</td>\n",
       "      <td>wonder able overnight jacket item trenton nj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Swingline electronic stapler (472555) look...</td>\n",
       "      <td>Shipping</td>\n",
       "      <td>swingline electronic stapler look great need s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I think this cosmetic bag would work great for...</td>\n",
       "      <td>Shipping</td>\n",
       "      <td>think cosmetic bag work great know long send k...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question             topic  \\\n",
       "0  Hi! If I sign up for your email list, can I se...  Sales/Promotions   \n",
       "1  I'm going to be out of the country for about a...          Shipping   \n",
       "2  I was wondering if you'd be able to overnight ...          Shipping   \n",
       "3  The Swingline electronic stapler (472555) look...          Shipping   \n",
       "4  I think this cosmetic bag would work great for...          Shipping   \n",
       "\n",
       "                                      clean_question  \n",
       "0  hi sign email list select email exclusively sa...  \n",
       "1  go country week travel go get animal print jum...  \n",
       "2       wonder able overnight jacket item trenton nj  \n",
       "3  swingline electronic stapler look great need s...  \n",
       "4  think cosmetic bag work great know long send k...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to clean words using spacy\n",
    "def clean_spacy_text(doc, exclude:list=[]):\n",
    "    # patterns for removing products/website i.e. alphanumeric product item/asin dash \"-\", number or slash \"\\\" for products\n",
    "    pattern = re.compile(r\"[a-zA-Z]+\\d+[a-zA-Z\\d]+|\\(.+\\)|\\w+\\-\\d+/\\d+|\\d+[-]*|#\\w+|[\\w]+\\-[\\d]+\\-[\\d]+|\\w+-\\d+\" , flags=re.IGNORECASE | re.DOTALL)\n",
    "    # using list comprehensition to do a single pass cleaning\n",
    "    words = [token.lemma_.lower() for token in doc if (not token.is_punct and                                   # removes punctuation\n",
    "                                                       not token.is_stop and                                    # removes whitespace\n",
    "                                                       not token.is_space and                                   # removes stop word\n",
    "                                                       token.pos_ != 'NUM' and                                  # removes numbers\n",
    "                                                       not bool(re.match(pattern, token.text.lower())) and      # removes token matches of product ids\n",
    "                                                       (len(token.text) > 1 or token.text == 'e')and            # removes len text greater than 1 unless e for email\n",
    "                                                       token.lemma_ not in exclude)                             # removes not in exclude list\n",
    "                                                       ]\n",
    "    text = ' '.join(words)\n",
    "    # fix email\n",
    "    text = text.replace('e mail', 'email')\n",
    "    # replace missing punct at end of words i.e. word- or word\\\\\n",
    "    text = re.sub(r\"[$/_\\\\-]+\", \" \", text)\n",
    "    # remove website links\n",
    "    text = re.sub(r\"\\(?https?\\S+\", \"\", text)\n",
    "    # remove single #item\n",
    "    text = re.sub(r\"#\\S+\", \"\", text)\n",
    "    # apped to list of all docs\n",
    "    return text\n",
    "\n",
    "# # iterate through docs apply cleaning\n",
    "cleaned_text = list()\n",
    "for doc in corpus:\n",
    "    text = clean_spacy_text(doc, exclude=[])\n",
    "    cleaned_text.append(text)\n",
    "\n",
    "\n",
    "\n",
    "# add to pandas dataframe\n",
    "data['clean_question'] = cleaned_text\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encoding label\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(data.topic)\n",
    "# train data to numpy\n",
    "X = data.clean_question.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Train-Test\n",
    "\n",
    "Because of the small sample size and noting that there a lot of synthetic samples, it is preferrable to use a larger training size at 75%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape X: 4250, y: 4250\n",
      "Test shape X: 750, y: 750\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# seed for replication\n",
    "seed = 42\n",
    "\n",
    "# Splitting data\n",
    "def get_data_split(X, y, test_size=.15):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)\n",
    "    if isinstance(X, list):\n",
    "        X_train_size = len(X_train)\n",
    "        X_test_size = len(X_test)\n",
    "    else:\n",
    "        X_train_size = X_train.shape[0]\n",
    "        X_test_size = X_test.shape[0]\n",
    "    print('Train shape X: {}, y: {}'.format(X_train_size, y_train.shape[0]))\n",
    "    print('Test shape X: {}, y: {}'.format(X_test_size, y_test.shape[0]))\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_data_split(X, y, test_size=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "- settiing options to include one and bi-grams\n",
    "- Setting max number of features to stop feature explosion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: interested get sumptuous knockout mascara wonder waterproof salt water let know live near ocean want run beach\n",
      "After:\n",
      "   (0, 4773)\t0.31765703623176056\n",
      "  (0, 2132)\t0.2650402074551438\n",
      "  (0, 256)\t0.30062724791207285\n",
      "  (0, 3625)\t0.24013115993458056\n",
      "  (0, 4723)\t0.11310998666141832\n",
      "  (0, 2597)\t0.24480270622493278\n",
      "  (0, 2245)\t0.24868244348656238\n",
      "  (0, 1944)\t0.11979080339388229\n",
      "  (0, 2131)\t0.25295738035300025\n",
      "  (0, 4801)\t0.24605654936208105\n",
      "  (0, 3659)\t0.2223709075355655\n",
      "  (0, 4805)\t0.25606996156736833\n",
      "  (0, 4934)\t0.17187577356234895\n",
      "  (0, 2444)\t0.2764615937077858\n",
      "  (0, 4276)\t0.31765703623176056\n",
      "  (0, 1466)\t0.20992755782584938\n",
      "  (0, 1760)\t0.20345313279075153 \n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "Shape of X_train: (4250, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "N_GRAMS = (1,3)                                         # Selecting Grams from 1-3 words\n",
    "MAX_FEATURES = 5000                                     # Limiting the amount of features to help processing speed\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    ngram_range=N_GRAMS,\n",
    "    max_features=MAX_FEATURES)\n",
    "\n",
    "# Fit & Preview Changes\n",
    "print('Before:', X_train[0])\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "print('After:\\n {} \\n{}'.format(X_train_tfidf[0], type(X_train_tfidf[0])))\n",
    "print('Shape of X_train:', X_train_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec\n",
    "\n",
    "Because of the smaller text size we are only using 100D per word embeddings - lower dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape X: 4250, y: 4250\n",
      "Test shape X: 750, y: 750\n"
     ]
    }
   ],
   "source": [
    "# Creating sentence -> list of tokens\n",
    "def sent_tokenizer(X_data):\n",
    "    X_sent_tokens = []\n",
    "    for line in X_data: \n",
    "        sent = [word for word in line.split()]\n",
    "        X_sent_tokens.append(sent)\n",
    "    return X_sent_tokens\n",
    "\n",
    "X_sent_tokens = sent_tokenizer(X)\n",
    "\n",
    "# get tokens in list format\n",
    "X_train, X_test, y_train, y_test = get_data_split(X_sent_tokens, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features shape: (4250, 100) \n",
      "Test features shape: (750, 100)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "EMBEDDING_DIM = 100                                                             # Limiting the number of Embedding dimensions for relatively small dataset should be enough\n",
    "\n",
    "# Training W2V\n",
    "w2v = Word2Vec(X_train, window=8, min_count=2, sample=1e-3, sg=1, workers=8)\n",
    "vocab = set(w2v.wv.index_to_key)\n",
    "\n",
    "# Function to generate average vectors\n",
    "def average_word_vectors(tokens, model, vocabulary, num_features):\n",
    "    feature_vector = np.zeros((num_features,), dtype=\"float64\")\n",
    "    ntokens = 0.\n",
    "    for t in tokens:\n",
    "        if t in vocabulary: \n",
    "            ntokens = ntokens + 1.\n",
    "            feature_vector = np.add(feature_vector, model.wv[t])\n",
    "    if ntokens:\n",
    "        feature_vector = np.divide(feature_vector, ntokens)\n",
    "    return feature_vector\n",
    "\n",
    "# Creating average 100D embeddings per token sentences \n",
    "w2v_train_x = [average_word_vectors(sent_tokens, w2v, vocab, EMBEDDING_DIM) \n",
    "               for sent_tokens in X_train]\n",
    "w2v_test_x = [average_word_vectors(sent_tokens, w2v, vocab, EMBEDDING_DIM) \n",
    "              for sent_tokens in X_test]\n",
    "# To Arrays\n",
    "avg_w2v_train_x = np.array(w2v_train_x)              \n",
    "avg_w2v_test_x = np.array(w2v_test_x)\n",
    "\n",
    "print('Train features shape:', avg_w2v_train_x.shape, \n",
    "      '\\nTest features shape:', avg_w2v_test_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "# Training Doc2Vec\n",
    "docs = [TaggedDocument(doc, [i]) for i, doc in enumerate(X_train)]\n",
    "d2v = Doc2Vec(vector_size=100, window=3, min_count=4, workers=4, epochs=40)\n",
    "d2v.build_vocab(docs)\n",
    "d2v.train(docs, total_examples=d2v.corpus_count, epochs=d2v.epochs)\n",
    "\n",
    "# d2v embedded sets\n",
    "d2v_train_x = [d2v.infer_vector(i) for i in X_train]\n",
    "d2v_test_x =  [d2v.infer_vector(i) for i in X_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Datasets prepared for Modeling\n",
    "Creating a master dataset dictionary to be used across models for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictonary of datasets\n",
    "datasets = {\n",
    "    'TFIDF': {\n",
    "        'train': X_train_tfidf,\n",
    "        'test': X_test_tfidf\n",
    "    },\n",
    "    'Avg W2V Data': {\n",
    "        'train': avg_w2v_train_x,\n",
    "        'test': avg_w2v_test_x,\n",
    "    },\n",
    "    'Doc2Vector Data': {\n",
    "        'train': d2v_train_x,\n",
    "        'test': d2v_test_x\n",
    "    }\n",
    "}\n",
    "# Dictionary of labels\n",
    "labels = {\n",
    "    'train': y_train,\n",
    "    'test': y_test\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models for text classification\n",
    "Creating a master function that will help us evaluate the multiple models that we will be using for classification.\n",
    "\n",
    "For our models we will be using the weighted F1-score as the main evalution to rate it's performance. This allows us to see the weighted effectiveness of our model in capturing most classes (recall) and getting our class predictions correctly (precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, f1_score, recall_score, precision_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.base import clone\n",
    "\n",
    "def fit_score(model, model_name, datasets, labels):\n",
    "    list_scores = list()\n",
    "    models = list()\n",
    "    for name, data in datasets.items():\n",
    "        # getting diff model for fitting\n",
    "        model = clone(model)\n",
    "        print(f'Dataset: {name}')\n",
    "        # fit model\n",
    "        model.fit(data['train'], labels['train'])\n",
    "        # cross-validate score\n",
    "        cross_val = cross_val_score(model, X=data['train'], y=labels['train'], scoring='f1_weighted')\n",
    "        print(f'CV Weighted F1-Scores: {cross_val}')\n",
    "        print('Avg CV Score: {}'.format(np.mean(cross_val)))\n",
    "        # predict\n",
    "        y_predict = model.predict(data['test'])\n",
    "        # classification report\n",
    "        target_names = encoder.classes_\n",
    "        # print report\n",
    "        print(classification_report(labels['test'], y_predict, target_names=target_names))\n",
    "        # soring function to iterate\n",
    "        scores_functions = {'Precision':precision_score, 'Recall':recall_score, 'F1 Score': f1_score}\n",
    "        # dictionary for model\n",
    "        model_scores = {'Model': model_name, 'Dataset': name}\n",
    "        # add scores\n",
    "        for name, function in scores_functions.items():\n",
    "            score = function(y_predict, labels['test'], average='weighted')\n",
    "            model_scores[name] = score\n",
    "        # insert into list of scores\n",
    "        list_scores.append(model_scores)\n",
    "        models.append(model)\n",
    "    return models, list_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM (LinearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: TFIDF\n",
      "CV Weighted F1-Scores: [0.94716739 0.9423865  0.95523986 0.94807148 0.94356655]\n",
      "Avg CV Score: 0.9472863561949751\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           Omnichannel       1.00      1.00      1.00        68\n",
      "  Product Availability       0.93      0.95      0.94       131\n",
      "    Product Comparison       0.90      0.92      0.91       113\n",
      "Product Specifications       0.91      0.91      0.91       117\n",
      "     Returns & Refunds       0.99      1.00      1.00       124\n",
      "      Sales/Promotions       1.00      0.94      0.97        82\n",
      "              Shipping       1.00      1.00      1.00       115\n",
      "\n",
      "              accuracy                           0.96       750\n",
      "             macro avg       0.96      0.96      0.96       750\n",
      "          weighted avg       0.96      0.96      0.96       750\n",
      "\n",
      "Dataset: Avg W2V Data\n",
      "CV Weighted F1-Scores: [0.839214   0.85561033 0.84137026 0.85069685 0.82721351]\n",
      "Avg CV Score: 0.8428209899624791\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           Omnichannel       0.97      0.97      0.97        68\n",
      "  Product Availability       0.86      0.89      0.87       131\n",
      "    Product Comparison       0.80      0.66      0.72       113\n",
      "Product Specifications       0.71      0.79      0.74       117\n",
      "     Returns & Refunds       0.98      0.96      0.97       124\n",
      "      Sales/Promotions       0.99      0.96      0.98        82\n",
      "              Shipping       0.94      0.99      0.97       115\n",
      "\n",
      "              accuracy                           0.88       750\n",
      "             macro avg       0.89      0.89      0.89       750\n",
      "          weighted avg       0.88      0.88      0.88       750\n",
      "\n",
      "Dataset: Doc2Vector Data\n",
      "CV Weighted F1-Scores: [0.57934288 0.59322973 0.61371623 0.60068918 0.58654889]\n",
      "Avg CV Score: 0.5947053806139289\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           Omnichannel       0.62      0.68      0.65        68\n",
      "  Product Availability       0.55      0.63      0.59       131\n",
      "    Product Comparison       0.49      0.47      0.48       113\n",
      "Product Specifications       0.46      0.46      0.46       117\n",
      "     Returns & Refunds       0.62      0.56      0.59       124\n",
      "      Sales/Promotions       0.66      0.49      0.56        82\n",
      "              Shipping       0.59      0.65      0.62       115\n",
      "\n",
      "              accuracy                           0.56       750\n",
      "             macro avg       0.57      0.56      0.56       750\n",
      "          weighted avg       0.56      0.56      0.56       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Initiating simple mode\n",
    "svc = LinearSVC()\n",
    "\n",
    "# Fitting and Scoring\n",
    "[svc_tfidf, svc_w2v, svc_d2v], scores = fit_score(svc, 'SV Classifier', datasets, labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC appears to do pretty well in classification of document types especially when using the TFIDF method. I believe that the embedding that we attempted had too small of a data sample to be able to be trained properly. I tried to do transfer learning approaches but did not have a clear understanding of how to use them in gensim. The function (intersect_word2vec_format) that use to exist for this appeard to not be working in my latest version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SV Classifier</td>\n",
       "      <td>TFIDF</td>\n",
       "      <td>0.957385</td>\n",
       "      <td>0.957333</td>\n",
       "      <td>0.957238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SV Classifier</td>\n",
       "      <td>Avg W2V Data</td>\n",
       "      <td>0.885674</td>\n",
       "      <td>0.881333</td>\n",
       "      <td>0.882211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SV Classifier</td>\n",
       "      <td>Doc2Vector Data</td>\n",
       "      <td>0.566537</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.561100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model          Dataset  Precision    Recall  F1 Score\n",
       "0  SV Classifier            TFIDF   0.957385  0.957333  0.957238\n",
       "1  SV Classifier     Avg W2V Data   0.885674  0.881333  0.882211\n",
       "2  SV Classifier  Doc2Vector Data   0.566537  0.560000  0.561100"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display SVC Scores\n",
    "pd.DataFrame(scores).sort_values('F1 Score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: TFIDF\n",
      "CV Weighted F1-Scores: [0.93184506 0.94563494 0.94249841 0.94816488 0.93583199]\n",
      "Avg CV Score: 0.9407950552169991\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           Omnichannel       0.99      0.97      0.98        68\n",
      "  Product Availability       0.93      0.98      0.96       131\n",
      "    Product Comparison       0.93      0.94      0.93       113\n",
      "Product Specifications       0.93      0.91      0.92       117\n",
      "     Returns & Refunds       0.98      1.00      0.99       124\n",
      "      Sales/Promotions       1.00      0.93      0.96        82\n",
      "              Shipping       1.00      0.99      1.00       115\n",
      "\n",
      "              accuracy                           0.96       750\n",
      "             macro avg       0.97      0.96      0.96       750\n",
      "          weighted avg       0.96      0.96      0.96       750\n",
      "\n",
      "Dataset: Avg W2V Data\n",
      "CV Weighted F1-Scores: [0.90034004 0.91953115 0.90127875 0.90495221 0.88368582]\n",
      "Avg CV Score: 0.9019575945526329\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           Omnichannel       0.97      0.94      0.96        68\n",
      "  Product Availability       0.92      0.92      0.92       131\n",
      "    Product Comparison       0.83      0.86      0.84       113\n",
      "Product Specifications       0.83      0.81      0.82       117\n",
      "     Returns & Refunds       0.97      0.99      0.98       124\n",
      "      Sales/Promotions       0.97      0.95      0.96        82\n",
      "              Shipping       0.99      1.00      1.00       115\n",
      "\n",
      "              accuracy                           0.92       750\n",
      "             macro avg       0.93      0.92      0.93       750\n",
      "          weighted avg       0.92      0.92      0.92       750\n",
      "\n",
      "Dataset: Doc2Vector Data\n",
      "CV Weighted F1-Scores: [0.71990639 0.70907089 0.74500782 0.72563841 0.73520274]\n",
      "Avg CV Score: 0.7269652497621933\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           Omnichannel       0.82      0.85      0.83        68\n",
      "  Product Availability       0.80      0.86      0.83       131\n",
      "    Product Comparison       0.65      0.58      0.62       113\n",
      "Product Specifications       0.61      0.71      0.66       117\n",
      "     Returns & Refunds       0.77      0.75      0.76       124\n",
      "      Sales/Promotions       0.93      0.70      0.80        82\n",
      "              Shipping       0.75      0.77      0.76       115\n",
      "\n",
      "              accuracy                           0.75       750\n",
      "             macro avg       0.76      0.75      0.75       750\n",
      "          weighted avg       0.75      0.75      0.75       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "# Fitting and Scoring\n",
    "[rfc_tfidf, rfc_w2v, rfc_d2v], rfc_scores = fit_score(rfc, 'RF Classifier', datasets, labels)\n",
    "\n",
    "# adding rfc scores to scores\n",
    "scores.extend(rfc_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the RF Classifier performs better in comparison to the SV Classifier across all dataset. The difference in performance is more noticeable in the two embedded datasets, but only slight (F1 = +.04%) for the TfiDf dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF Classifier</td>\n",
       "      <td>TFIDF</td>\n",
       "      <td>0.962100</td>\n",
       "      <td>0.961333</td>\n",
       "      <td>0.961376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SV Classifier</td>\n",
       "      <td>TFIDF</td>\n",
       "      <td>0.957385</td>\n",
       "      <td>0.957333</td>\n",
       "      <td>0.957238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RF Classifier</td>\n",
       "      <td>Avg W2V Data</td>\n",
       "      <td>0.923030</td>\n",
       "      <td>0.922667</td>\n",
       "      <td>0.922724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SV Classifier</td>\n",
       "      <td>Avg W2V Data</td>\n",
       "      <td>0.885674</td>\n",
       "      <td>0.881333</td>\n",
       "      <td>0.882211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RF Classifier</td>\n",
       "      <td>Doc2Vector Data</td>\n",
       "      <td>0.750537</td>\n",
       "      <td>0.745333</td>\n",
       "      <td>0.745267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SV Classifier</td>\n",
       "      <td>Doc2Vector Data</td>\n",
       "      <td>0.566537</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.561100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model          Dataset  Precision    Recall  F1 Score\n",
       "3  RF Classifier            TFIDF   0.962100  0.961333  0.961376\n",
       "0  SV Classifier            TFIDF   0.957385  0.957333  0.957238\n",
       "4  RF Classifier     Avg W2V Data   0.923030  0.922667  0.922724\n",
       "1  SV Classifier     Avg W2V Data   0.885674  0.881333  0.882211\n",
       "5  RF Classifier  Doc2Vector Data   0.750537  0.745333  0.745267\n",
       "2  SV Classifier  Doc2Vector Data   0.566537  0.560000  0.561100"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying top candidates\n",
    "pd.DataFrame(scores).sort_values('F1 Score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF Keras Deep Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.utils import np_utils\n",
    "\n",
    "def deep_learner_classifier(classes:int, dropout_p:float, activation:str, input_shape:tuple):\n",
    "    \"\"\"Basic Deep Learner Classifer for text\n",
    "\n",
    "    Args:\n",
    "        classes (int): number of classes to predict\n",
    "        dropout_p (float): percentage of drop out per each layer\n",
    "        activation (str): type of activation function to be used per layer\n",
    "        input_shape (tuple): shape of the input for the first layer\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.models.Sequential: a model compiled for fitting\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1024, input_shape=input_shape))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dropout(dropout_p))\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dropout(dropout_p))\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dropout(dropout_p))\n",
    "    model.add(Dense(classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Parameters & Encoding Labels\n",
    "\n",
    "Setting general params that can be used accross models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Parameters\n",
    "CLASSES = len(encoder.classes_)\n",
    "BATCH_SIZE = 64\n",
    "DROPOUT = 0.1\n",
    "ACTIVATION = 'relu'\n",
    "\n",
    "# Crating One-Hot Econders for Categories\n",
    "y_train_tf = np_utils.to_categorical(y_train, CLASSES)\n",
    "y_test_tf = np_utils.to_categorical(y_test, CLASSES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_deep_learner(model, X_test, model_name, data_name):\n",
    "    # true labels\n",
    "    y_true = [np.argmax(arr) for arr in y_test_tf]\n",
    "    # predict\n",
    "    y_predict = [np.argmax(arr) for arr in model.predict(X_test)]\n",
    "    # classification report\n",
    "    target_names = encoder.classes_\n",
    "    # print report\n",
    "    print(classification_report(y_true, y_predict, target_names=target_names))\n",
    "    # soring function to iterate\n",
    "    scores_functions = {'Precision':precision_score, 'Recall':recall_score, 'F1 Score': f1_score}\n",
    "    # dictionary for model\n",
    "    model_scores = {'Model': model_name, 'Dataset': data_name}\n",
    "    # add scores\n",
    "    for name, function in scores_functions.items():\n",
    "        score = function(y_predict, y_true, average='weighted')\n",
    "        model_scores[name] = score\n",
    "    return model_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF Deep Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-17 23:07:25.988234: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-10-17 23:07:26.593309: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "67/67 [==============================] - 3s 29ms/step - loss: 0.7674 - accuracy: 0.7696 - val_loss: 0.1748 - val_accuracy: 0.9387\n",
      "Epoch 2/5\n",
      "67/67 [==============================] - 2s 26ms/step - loss: 0.0900 - accuracy: 0.9734 - val_loss: 0.1212 - val_accuracy: 0.9587\n",
      "Epoch 3/5\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 0.0326 - accuracy: 0.9904 - val_loss: 0.1342 - val_accuracy: 0.9653\n",
      "Epoch 4/5\n",
      "67/67 [==============================] - 3s 40ms/step - loss: 0.0167 - accuracy: 0.9960 - val_loss: 0.1476 - val_accuracy: 0.9547\n",
      "Epoch 5/5\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 0.0125 - accuracy: 0.9969 - val_loss: 0.1298 - val_accuracy: 0.9640\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           Omnichannel       1.00      1.00      1.00        68\n",
      "  Product Availability       0.92      0.98      0.95       131\n",
      "    Product Comparison       0.93      0.91      0.92       113\n",
      "Product Specifications       0.93      0.91      0.92       117\n",
      "     Returns & Refunds       1.00      1.00      1.00       124\n",
      "      Sales/Promotions       1.00      0.95      0.97        82\n",
      "              Shipping       1.00      1.00      1.00       115\n",
      "\n",
      "              accuracy                           0.96       750\n",
      "             macro avg       0.97      0.96      0.97       750\n",
      "          weighted avg       0.96      0.96      0.96       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Params for TFIDF\n",
    "INPUT_SHAPE = (5000,)                                           # Matching the size of the vocab vectors\n",
    "EPOCHS = 5                                                      # Limiting amount of epochs for trial\n",
    "\n",
    "# Initializing model\n",
    "tfidf_dl = deep_learner_classifier(classes=CLASSES, dropout_p=DROPOUT, activation=ACTIVATION, input_shape=INPUT_SHAPE)\n",
    "\n",
    "# Fitting\n",
    "tfidf_dl.fit(X_train_tfidf.toarray(), y_train_tf, validation_data=(X_test_tfidf.toarray(), y_test_tf), batch_size=BATCH_SIZE, epochs=EPOCHS)\n",
    "\n",
    "# Score\n",
    "tfidf_dl_score = score_deep_learner(tfidf_dl, X_test_tfidf.toarray(), 'Deep Learner', 'TFIDF')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avg. Word2Vec Deep Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "67/67 [==============================] - 1s 9ms/step - loss: 0.7904 - accuracy: 0.7096 - val_loss: 0.4563 - val_accuracy: 0.7933\n",
      "Epoch 2/5\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.4968 - accuracy: 0.7899 - val_loss: 0.4195 - val_accuracy: 0.8147\n",
      "Epoch 3/5\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.4347 - accuracy: 0.8054 - val_loss: 0.3962 - val_accuracy: 0.8253\n",
      "Epoch 4/5\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.3947 - accuracy: 0.8308 - val_loss: 0.3769 - val_accuracy: 0.8373\n",
      "Epoch 5/5\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.3852 - accuracy: 0.8313 - val_loss: 0.3702 - val_accuracy: 0.8227\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           Omnichannel       0.90      0.96      0.93        68\n",
      "  Product Availability       0.85      0.89      0.87       131\n",
      "    Product Comparison       0.53      0.90      0.67       113\n",
      "Product Specifications       0.87      0.22      0.35       117\n",
      "     Returns & Refunds       0.92      0.98      0.95       124\n",
      "      Sales/Promotions       1.00      0.93      0.96        82\n",
      "              Shipping       0.99      0.96      0.97       115\n",
      "\n",
      "              accuracy                           0.82       750\n",
      "             macro avg       0.87      0.83      0.81       750\n",
      "          weighted avg       0.86      0.82      0.80       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Params for Avg Word2Vec\n",
    "INPUT_SHAPE = (100,)                                                            # Matching the size of the embedded vectors\n",
    "EPOCHS = 5                                                                      # Number of training epochs limited as very little validation loss experienced before signs of overfitting in training\n",
    "\n",
    "# Initializing model\n",
    "w2v_dl = deep_learner_classifier(classes=CLASSES, dropout_p=DROPOUT, activation=ACTIVATION, input_shape=INPUT_SHAPE)\n",
    "\n",
    "\n",
    "# Fitting\n",
    "w2v_dl.fit(avg_w2v_train_x, y_train_tf, validation_data=(avg_w2v_test_x, y_test_tf), batch_size=BATCH_SIZE, epochs=EPOCHS)\n",
    "\n",
    "# Score\n",
    "w2v_dl_score = score_deep_learner(w2v_dl, avg_w2v_test_x, 'Deep Learner', 'Avg W2V Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2Vec Deep Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "67/67 [==============================] - 1s 11ms/step - loss: 1.5117 - accuracy: 0.4261 - val_loss: 1.2299 - val_accuracy: 0.5573\n",
      "Epoch 2/5\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 1.0930 - accuracy: 0.6115 - val_loss: 1.0712 - val_accuracy: 0.6253\n",
      "Epoch 3/5\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.8718 - accuracy: 0.7075 - val_loss: 0.9523 - val_accuracy: 0.6693\n",
      "Epoch 4/5\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.7024 - accuracy: 0.7664 - val_loss: 0.8269 - val_accuracy: 0.7307\n",
      "Epoch 5/5\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.5565 - accuracy: 0.8174 - val_loss: 0.8404 - val_accuracy: 0.7347\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           Omnichannel       0.33      0.29      0.31        68\n",
      "  Product Availability       0.35      0.50      0.41       131\n",
      "    Product Comparison       0.23      0.46      0.30       113\n",
      "Product Specifications       0.33      0.12      0.18       117\n",
      "     Returns & Refunds       0.41      0.37      0.39       124\n",
      "      Sales/Promotions       0.48      0.17      0.25        82\n",
      "              Shipping       0.31      0.23      0.26       115\n",
      "\n",
      "              accuracy                           0.32       750\n",
      "             macro avg       0.35      0.31      0.30       750\n",
      "          weighted avg       0.34      0.32      0.30       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Params for Doc2Vec\n",
    "INPUT_SHAPE = (100,)                                                            # Matching the size of the embedded vectors\n",
    "EPOCHS = 5                                                                      # Number of training epochs limited as very little validation loss experienced before signs of overfitting in training\n",
    "\n",
    "# Initializing model\n",
    "d2v_dl = deep_learner_classifier(classes=CLASSES, dropout_p=DROPOUT, activation=ACTIVATION, input_shape=INPUT_SHAPE)\n",
    "\n",
    "\n",
    "# Fitting\n",
    "d2v_dl.fit(np.array(d2v_train_x), y_train_tf, validation_data=(np.array(d2v_test_x), y_test_tf), batch_size=BATCH_SIZE, epochs=EPOCHS)\n",
    "\n",
    "# Score\n",
    "d2v_dl_score = score_deep_learner(w2v_dl, np.array(d2v_test_x), 'Deep Learner', 'Doc2Vector Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that out of all the Deep Learning models attempted the one with the TFIDF data appears to perform best in comparison to the W2V and D2V models by 10-20% more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appending DL Scores \n",
    "scores.append(tfidf_dl_score)\n",
    "scores.append(w2v_dl_score)\n",
    "scores.append(d2v_dl_score)\n",
    "\n",
    "scores_df = pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "While the Deep Learner and Random Forest Classifier performed best, out of the three models and data transformations attempted for text classification, I would pick the SVC with TfiDf simply because it provides only slightly smaller f1-score (0.07%) than the next best model while providing the most simplicity. This makes this model easier to undestand, avoids overfitting and provides faster performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Deep Learner</td>\n",
       "      <td>TFIDF</td>\n",
       "      <td>0.964689</td>\n",
       "      <td>0.964000</td>\n",
       "      <td>0.964050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF Classifier</td>\n",
       "      <td>TFIDF</td>\n",
       "      <td>0.962100</td>\n",
       "      <td>0.961333</td>\n",
       "      <td>0.961376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SV Classifier</td>\n",
       "      <td>TFIDF</td>\n",
       "      <td>0.957385</td>\n",
       "      <td>0.957333</td>\n",
       "      <td>0.957238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RF Classifier</td>\n",
       "      <td>Avg W2V Data</td>\n",
       "      <td>0.923030</td>\n",
       "      <td>0.922667</td>\n",
       "      <td>0.922724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SV Classifier</td>\n",
       "      <td>Avg W2V Data</td>\n",
       "      <td>0.885674</td>\n",
       "      <td>0.881333</td>\n",
       "      <td>0.882211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Deep Learner</td>\n",
       "      <td>Avg W2V Data</td>\n",
       "      <td>0.902260</td>\n",
       "      <td>0.822667</td>\n",
       "      <td>0.842001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RF Classifier</td>\n",
       "      <td>Doc2Vector Data</td>\n",
       "      <td>0.750537</td>\n",
       "      <td>0.745333</td>\n",
       "      <td>0.745267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SV Classifier</td>\n",
       "      <td>Doc2Vector Data</td>\n",
       "      <td>0.566537</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.561100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Deep Learner</td>\n",
       "      <td>Doc2Vector Data</td>\n",
       "      <td>0.387774</td>\n",
       "      <td>0.317333</td>\n",
       "      <td>0.329950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model          Dataset  Precision    Recall  F1 Score\n",
       "6   Deep Learner            TFIDF   0.964689  0.964000  0.964050\n",
       "3  RF Classifier            TFIDF   0.962100  0.961333  0.961376\n",
       "0  SV Classifier            TFIDF   0.957385  0.957333  0.957238\n",
       "4  RF Classifier     Avg W2V Data   0.923030  0.922667  0.922724\n",
       "1  SV Classifier     Avg W2V Data   0.885674  0.881333  0.882211\n",
       "7   Deep Learner     Avg W2V Data   0.902260  0.822667  0.842001\n",
       "5  RF Classifier  Doc2Vector Data   0.750537  0.745333  0.745267\n",
       "2  SV Classifier  Doc2Vector Data   0.566537  0.560000  0.561100\n",
       "8   Deep Learner  Doc2Vector Data   0.387774  0.317333  0.329950"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df.sort_values('F1 Score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Out-of-Sample Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "# Create pipeline func for cleaning tfidf, word2vec, doc2vec\n",
    "def predict_pipeline(model, data, labels, transformation, deep_learner=False):\n",
    "    # convert to spacy and clean\n",
    "    nlp = spacy.load(library)\n",
    "    docs = [clean_spacy_text(nlp(text)) for text in data]\n",
    "    # transformation type\n",
    "    if transformation == 'tfidf':\n",
    "        docs = tfidf.transform(docs)\n",
    "    if transformation == 'word2vec':\n",
    "        docs = sent_tokenizer(docs)\n",
    "        docs = [average_word_vectors(doc, w2v, vocab, EMBEDDING_DIM) for doc in docs]\n",
    "    if transformation == 'doc2vec':\n",
    "        docs = sent_tokenizer(docs)\n",
    "        docs = [d2v.infer_vector(doc) for doc in docs]\n",
    "    # make predictions\n",
    "    if deep_learner:\n",
    "        if transformation == 'tfidf':\n",
    "            docs = docs.toarray()\n",
    "        if transformation == 'doc2vec':\n",
    "            docs = np.array(docs)\n",
    "        predictions = [np.array(np.argmax(arr)) for arr in model.predict(docs)]\n",
    "    else:\n",
    "        predictions = model.predict(docs)\n",
    "    print('Actual --> Predicted')\n",
    "    for i, pred in enumerate(predictions):\n",
    "        print(\"['{1}'] --> {0}\".format(encoder.inverse_transform(pred.ravel()), labels[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC - TFIDF\n",
      "Actual --> Predicted\n",
      "['Shipping'] --> ['Shipping']\n",
      "['Returns & Refunds'] --> ['Returns & Refunds']\n",
      "['Sales/Promotions'] --> ['Sales/Promotions']\n",
      "['Product Availability'] --> ['Product Availability']\n",
      "['Product Specification'] --> ['Product Availability']\n",
      "\n",
      "RFC - TFIDF\n",
      "Actual --> Predicted\n",
      "['Shipping'] --> ['Shipping']\n",
      "['Returns & Refunds'] --> ['Returns & Refunds']\n",
      "['Sales/Promotions'] --> ['Sales/Promotions']\n",
      "['Product Availability'] --> ['Product Availability']\n",
      "['Product Specification'] --> ['Product Availability']\n",
      "\n",
      "Deep Learner - TFIDF\n",
      "Actual --> Predicted\n",
      "['Shipping'] --> ['Shipping']\n",
      "['Returns & Refunds'] --> ['Returns & Refunds']\n",
      "['Sales/Promotions'] --> ['Sales/Promotions']\n",
      "['Product Availability'] --> ['Product Availability']\n",
      "['Product Specification'] --> ['Product Availability']\n"
     ]
    }
   ],
   "source": [
    "text1 = \"Hello, I was wondering if you are able to provide expedite shipping for item (9292323) to Tampa, FL?\" # --> Shipping\n",
    "text2 = \"The polo shirt that I received is size small instead of the medium I ordered. Can you send me a return label? I should not have to pay for this either.\" #--> Returns\n",
    "text3 = \"Are there any promo codes available for products in your gaming and entertaiment?\" #--> Sales/Promotions\n",
    "text4 = \"Do you have any men's pants that I could buy? I really liked the last ones I purchased.\" #--> Product Availability\n",
    "text5 = \"How long does the battery for the IPhone 13 last? I am looking to upgrade my phone.\" #--> Product Specification\n",
    "oos_test = [text1, text2, text3, text4, text5]\n",
    "class_labels = ['Shipping', 'Returns & Refunds', 'Sales/Promotions', 'Product Availability', 'Product Specification']\n",
    "\n",
    "\n",
    "# Compare Predictions\n",
    "print('SVC - TFIDF')\n",
    "predict_pipeline(svc_tfidf, oos_test, class_labels, transformation='tfidf')\n",
    "print('\\nRFC - TFIDF')\n",
    "predict_pipeline(rfc_tfidf, oos_test, class_labels, transformation='tfidf')\n",
    "print('\\nDeep Learner - TFIDF')\n",
    "predict_pipeline(tfidf_dl, oos_test, class_labels, transformation='tfidf', deep_learner=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that SVC, RFC and Deep Learner with TFIDF are able to correctly classify 4/5 out of the five samples. They all faill to classify the last query meant for Product Specifications. I imagine that the second phrase with the word I am looking is probabily throwing off this prediction. To improve from this error pre-trained embeddings could be used in transfer learning along with RNN models that may be able to pick up that both sentences refer to the same item and the question is referring to the real interest for the customer. This should also be noted and potentially question marks should not be deleted from cleaning"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "03bfd060fb8b62b12cb6c2c7a2e99139baaf1a28976ffe5231208b56dd8dc23e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('ISM6930-CY7GBNHA': pipenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
